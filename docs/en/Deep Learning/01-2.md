---

title: Machine Learning
---


1. [Linear regression and correlation](https://shimon-k.github.io/AGI-Course/en/Deep%20Learning/01-2#Linear regression and correlation)
2. [Generative verse Disciminative approaches](https://shimon-k.github.io/AGI-Course/en/Deep%20Learning/01-2#Generative verse Disciminative approaches)
3. [Multiple tasks](https://shimon-k.github.io/AGI-Course/en/Deep%20Learning/01-2#Multiple tasks)
4. [Machine Learning tasks](https://shimon-k.github.io/AGI-Course/en/Deep%20Learning/01-2#Machine Learning tasks)







<a id="Linear regression and correlation"> </a>
## Linear regression and correlation


### Linear correlation and covariance matrix
<iframe width="760" height="365" src="https://www.youtube.com/embed/532siGy0b50" title="Linear correlation and covariance matrix" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
- The _"Multivariate Gaussian distribution"_ part of the video is based on [this](https://www.youtube.com/watch?app=desktop&v=gR3XMv4WkR8&ab_channel=LawrenceLeemis), [this](https://www.youtube.com/watch?v=eho8xH3E6mE&ab_channel=AlexanderIhler), [this](https://datascienceplus.com/understanding-the-covariance-matrix/), and [this](https://cs229.stanford.edu/section/gaussians.pdf; https://rich-d-wilkinson.github.io/MATH3030/7.1-definition-and-properties-of-the-mvn.html).
- Note that besides $r$ or pearson linear correlation between continuous variables, there are other correlation measures for other variable types: cremer for ordinal or categorical variables, and spirmann for ordinal. While pearson is for interval or ratio scale variables.
- Note also, that a single gaussian distribution is too simplistic assumption about general data, hence usually we use mixture of gaussians, i.e. where there are several blobs to represent actual data.
It is formulized as a weighted sum of multiple Gaussian distributions, each representing a cluster or component within the data: $p(\mathbf{x})=\sum\limits_{i=1}^{K}\omega_i\mathcal{N}(\mathbf{x}\|\mu_i,\Sigma_i)$ where $\sum\limits_{i=1}^{K}\omega_i=1$ make sure that the mixture weights form a valid probability distribution.
- This section is the base for the _Gaussian processes_ in the [Bayesian Learning]() section.


### Algebra clarifications
<iframe width="760" height="365" src="https://www.youtube.com/embed/TZ1Rm4iDqG0" title="Algebra clarifications" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
- More about linear transformations: [here](https://medium.com/recreational-maths/2d-transformation-matrices-f804b9a0daf8), [here](https://people.math.harvard.edu/~knill/teaching/math19b_2011/handouts/lecture08.pdf), and [here](https://interactivetextbooks.tudelft.nl/linear-algebra/Chapter3/GeometryofLinearTransformations.html).
- More about: [SVD](https://medium.com/intuition/the-mathematical-and-geographic-understanding-of-singular-value-decomposition-svd-8da2297797c6), [PCA](https://medium.com/intuition/mathematical-understanding-of-principal-component-analysis-6c761004c2f8), [eigen topic](https://joseph-mellor1999.medium.com/the-cayley-hamilton-theorem-dc6986747b23), and a [more simple algebra](https://medium.com/bitgrit-data-science-publication/linear-algebra-concepts-every-data-scientist-should-know-18b00bd453dd).


### Linear regression


- More about [regularizations](https://medium.com/intuition/understanding-l1-and-l2-regularization-with-analytical-and-probabilistic-views-8386285210fc), [kernels](https://medium.com/the-quantastic-journal/mathematical-understanding-of-gaussian-process-eaffc9c8a6d6?source=email-d1019811a9ed-1719532710769-digest.reader-cf522ff06849-eaffc9c8a6d6----4-102------------------2ec3adf7_5607_4125_ac7a_064ef8a30002-1), and [BLR](https://medium.com/intuition/gentle-introduction-of-bayesian-linear-regression-c83da6b0d1f7).




<a id="Generative verse Disciminative approaches"> </a>
## Generative verse Disciminative approaches





<a id="Multiple tasks"> </a>
## Multiple tasks




<a id="Machine Learning tasks"> </a>
## Machine Learning tasks
