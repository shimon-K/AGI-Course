---

title: State Space
---



Here we present AI-relevant Probability and Statistics mathematical necessary background.
1. [Abstract](https://shimon-k.github.io/AGI-Course/en/Deep%20Learning/01-1#INTRO)
2. [State space introduction](https://shimon-k.github.io/AGI-Course/en/Deep%20Learning/01-1#SS_Intro)
3. [State space in different fields](https://shimon-k.github.io/AGI-Course/en/Deep%20Learning/01-1#SS_Fields)
4. [State space in Classic AI](https://shimon-k.github.io/AGI-Course/en/Deep%20Learning/01-1#SS_Classic)
5. [Different state transition models](https://shimon-k.github.io/AGI-Course/en/Deep%20Learning/01-1#trans)
6. [Different policy learning techniques - DP and MC](https://shimon-k.github.io/AGI-Course/en/Deep%20Learning/01-1#DPMC)
7. [Different policy learning techniques - TD and more](https://shimon-k.github.io/AGI-Course/en/Deep%20Learning/01-1#TD)
8. [Summary](https://shimon-k.github.io/AGI-Course/en/Deep%20Learning/01-1#Summary)





<a id="INTRO"> </a>
## Abstract





<a id="SS_Intro"> </a>
## State space introduction

<iframe width="760" height="365" src="https://www.youtube.com/embed/0ZVlvGkWl-Q" title="Events" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
- _Simple_ event = one possible outcome of an experiment; _Complex_ event = a group of possible outcomes of an experiment.


<a id="SS_Fields"> </a>
## State space in different fields
<iframe width="760" height="365" src="https://www.youtube.com/embed/aIOwNwAxT8A" title="Distributions" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
- More fundamentally about randomness is [here](https://www.cantorsparadise.com/creating-randomness-eb512756c9c7).
- Pdf and Cdf are related via $f(x)=\frac{d}{dx}F(x)$, and they are used for example in [Sampling](https://shimon-k.github.io/AGI-Course/en/Deep%20Learning/01-1#Sampling methods).


<a id="SS_Classic"> </a>
## State space in Classic AI
<iframe width="760" height="365" src="https://www.youtube.com/embed/ni_CFo0eaRI" title="Statistics and distributions" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
- Range could be defined either as [minimum value, maximum value] or as a single value describing it, e.g. the mean of a range.
- [Here](https://medium.com/@Brain_Boost/gaussian-distribution-vs-poisson-distribution-195f780a2b4) for example, is about Poisson (which fits a specifc type of variable).
- The example with dice was taken from [here](https://web.stanford.edu/class/archive/cs/cs109/cs109.1226/).
<!-- - If instead we take sum of Xjâ€™s and divide by sqrt(n) instead of n, and by STD, and reduce the mean for each Xj, we get the standard normal distribution N(0,1).-->
- Unlike the dice example, going from sum of 1 variable, to a sum of 2 variables, and so on - we can see alternitavely calculating $X+Y$ by convolution of the $(X,Y)$ distribution. Performing it over and over multiple times derives the gaussian curve as CLT states. See this [here](https://www.youtube.com/watch?v=IaSGqQa5O-M&ab_channel=3Blue1Brown).
- More about Weak vs. Strong Law of large numbers can be found [here](https://readmedium.com/en/the-laws-of-large-numbers-af9f130ce5d0).
- Some sources for the "Bernoulli $\rightarrow$ Binomial $\rightarrow$ Normal distribution" derivation: [here](https://scipp.ucsc.edu/~haber/ph116C/NormalApprox.pdf), [here](https://www.youtube.com/watch?v=45K4kEXso2g), [here](https://www.m-hikari.com/imf/imf-2017/9-12-2017/p/baguiIMF9-12-2017.pdf), and [here](https://people.bath.ac.uk/pam28/Paul_Milewski,_Professor_of_Mathematics,_University_of_Bath/Past_Teaching_files/stirling.pdf). Also, there is _t-distribution_, which generalizes the standard normal distribution where the sample size is too small.


<a id="trans"> </a>
## Different state transition models
<iframe width="760" height="365" src="https://www.youtube.com/embed/EKuSTQE3jzg" title="Conditional probability" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
- If $A\perp B$ then also their completing counterparts and their combinations are also independent: $\overline{A}\perp B$ ; $A\perp \overline{B}$ ; $\overline{A}\perp \overline{B}$. 
- If $A$ and $B$ are mutually exlusive events (and $P(A),P(B)>0$),\
i.e. $P(A\cap B) = 0 \ne P(A)P(B)$, which means $A,B$ are not independent (i.e. dependent). And vice versa: $P(A\cap B) = P(A)P(B) \ne 0$.
- Note that all of what we talked about in this video is appropriate both for events or for random variables, since they are equivalent. And it is appropriate both for discrete probabilities ($p$) and continuous ones ($f$).


<a id="DPMC"> </a>
## Different policy learning techniques - DP and MC


<a id="TD"> </a>
## Different policy learning techniques - TD and more


<a id="Summary"> </a>
## Summary
